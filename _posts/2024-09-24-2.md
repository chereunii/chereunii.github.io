---
layout: post
title:  "4장 고객의 행동을 예측하는 테크닉 10"
date:   2024-09-24 
categories: Khuda 데이터분석 실무
---

계속해서 스포츠 센터의 데이터를 다뤄보자

3장에서 이용 이력을 집계한 결과에 고객 데이터를 결합한 customer_join.csv가 추가됐다. 여기서는 5개 데이터 중 use_log.csv와 customer_join.csv만 사용하자.

### 테크닉 31 데이터를 읽어 들이고 확인하자

```python
#데이터 불러오기, 결측치 수 표시
import pandas as pd
uselog = pd.read_csv('use_log.csv')
uselog.isnull().sum()

customer = pd.read_csv('customer_join.csv')
customer.isnull().sum()
```

### 테크닉 32 클러스터링으로 회원을 그룹화하자

```python
#customer의 mean, median, max,min,membership_period추출
customer_clustering = customer[["mean", "median", "max", "min", "membership_period"]]
customer_clustering.head()
```

자 이제 클러스터링 진행하자. 전통적인 클러스터링 방법으로 변수 간의 거리를 기반으로 그룹화를 진행하는 K-means이다.

여기서 4개의 그룹으로 지정할텐데 mean, median, max,min와 membership_period는 데이터가 크게 다르다. 그래서 membership_period를 표준화 진행하자.

```python
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
customer_clustering_sc = sc.fit_transform(customer_clustering)#데이터표준

#군집 수 4로 설정
kmeans = KMeans(n_clusters=4, random_state=0)
clusters = kmeans.fit(customer_clustering_sc)#표준화된 데이터로 군집화 수행
customer_clustering["cluster"] = clusters.labels_ 
print(customer_clustering["cluster"].unique())
customer_clustering.head()
```

![Untitled](/assets/HW1/gg11.png)

- `customer_clustering` 데이터프레임에 있는 데이터를 표준화한다.
- *`fit_transform()`*은 데이터를 표준화하고 변환된 데이터를 반환한다.
- `random_state=0`은 난수 시드를 고정하여 재현 가능한 결과를 얻기 위함이다.
- **`customer_clustering["cluster"] = clusters.labels_`**
    - 군집화 결과로 나온 각 데이터의 군집 레이블을 `customer_clustering` 데이터프레임에 **"cluster"**라는 새로운 열로 추가.

### 테크닉 33 클러스터링 결과를 분석하자

```python
#컬럼 이름 변경
customer_clustering.columns = ["월평균값", "월중앙값", "월최댓값", "월최솟값", "회원기간", "cluster"]
#클러스터마다 집계
customer_clustering.groupby("cluster").count()

#각 그룹마다 평균값 계산
customer_Clustering.groupby("cluster").mean()
```

### 테크닉 34 클러스터링 결과를 가시화하자

클러스터링에 사용한 변수는 5개이다. 5개의 변수를 2차원으로 그리기 위해 차원을 축소한다. **차원 축소**란 비지도학습의 일종으로 정보를 되도록 잃지 않게 하면서 새로운 축을 만드는 것이다.  여기서, 차원축소의 대표적인 방법인 **주성분 분석**을 사용한다. 

```python
from sklearn.decomposition import PCA
X = customer_clustering_sc
pca = PCA(n_components=2) #PCA객체 생성, 차원 2차원으로 줄이기. 데이터 2개의 주성분으로 축소
pca.fit(X) #학습시킴
x_pca = pca.transform(X) #2차원으로 변환해 저장
pca_df = pd.DataFrame(x_pca)
pca_df["cluster"] = customer_clustering["cluster"]

import matplotlib.pyplot as plt
%matplotlib inline #그래프 인라인으로 표시하도록 설정
for i in customer_clustering["cluster"].unique(): #클러스터 값들 순회하며 시각화 준비
    tmp = pca_df.loc[pca_df["cluster"] == i]#필터링해 tmp에 저장
    plt.scatter(tmp[0], tmp[1])

```

![Untitled](/assets/HW1/gg12.png)

`PCA`는 **주성분 분석(Principal Component Analysis)**을 위한 클래스입니다. 주성분 분석은 차원을 축소하는 기법으로, 데이터의 주요 특징을 유지하면서 차원을 줄여준다.

결과를 보면 깨끗하게 색깔 나뉘어져 있음. 깔끔하게 축소됐다는 것임. 

### 테크닉 35 클러스터링 결과를 바탕으로 탈퇴회원의 경향을 파악하자

탈퇴 회원을 특정하기 위해 is_delted열을 customer_clustering에 추가해 cluster및 is_delted별로 집계해보자.

```python
customer_clustering = pd.concat([customer_clustering, customer], axis=1)
customer_clustering.groupby(["cluster", "is_deleted"], as_index=False).count()[["cluster", "is_deleted", "customer_id"]]

```

1행

- `customer_clustering`와 `customer` 두 데이터프레임을 **열(column)** 기준으로 합친다. 즉, 각 데이터프레임의 열들이 병합되어 하나의 데이터프레임으로 합쳐짐.
- `axis=1`은 열을 기준으로 병합한다는 뜻이다.

2행

- `customer_clustering` 데이터프레임을 `cluster`와 `is_deleted` 열을 기준으로 그룹화한다.
- `as_index=False`는 그룹화된 열들이 인덱스가 아닌 일반 열로 유지되도록 설정한.

![Untitled](/assets/HW1/gg13.png)

정기적/비정기적 이용 여부를 살펴보자

```python
customer_clustering.groupby(["cluster", "routine_flg"], as_index=False).count()[["cluster", "routine_flg", "customer_id"]]
```

군집과 루틴 플래그(routine_flg)를 기준으로 고객 데이터를 그룹화하고, 각 그룹별로 고객 수(customer_id)를 집계하는 작업

이렇게 클러스터링을 통해 그룹화를 실시하면 고객의 특징 파악할 수 있다. 

### 테크닉 36 다음 달의 이용 횟수 예측을 위해 데이터를 준비하자

고객의 과거 행동 데이터로부터 다음 달의 이용 횟수를 예측하는 경우 지도학습의 회귀 분석을 이요한다**. 지도학습**은 미리 정답을 알고 있는 숫자 데이터를 이용해 예측한다.

이번에 예측하고 싶은 이용 횟수도 숫자 데이터라 지도학습의 회귀분석 가능하다. 

```python
#연월, 회원마다 데이터 집계
uselog["usedate"] = pd.to_datetime(uselog["usedate"])
uselog["연월"] = uselog["usedate"].dt.strftime("%Y%m")
uselog_months = uselog.groupby(["연월", "customer_id"], as_index=False).count()
uselog_months.rename(columns={"log_id":"count"}, inplace=True)
del uselog_months["usedate"]
uselog_months.head()

```

그리고 이번 달부터 과거 5개월분의 이용횟수, 다음달의 이용 횟수를 저장한다. 

```python
year_months = list(uselog_months["연월"].unique())
predict_data = pd.DataFrame()
for i in range(6, len(year_months)):
    tmp = uselog_months.loc[uselog_months["연월"] == year_months[i]]
    tmp.rename(columns={"count": "count_pred"}, inplace=True)#이름변경
    for j in range(1, 7):
        tmp_before = uselog_months.loc[uselog_months["연월"] == year_months[i-j]]
        del tmp_before["연월"]
        tmp_before.rename(columns={"count": "count_{}".format(j-1)}, inplace=True)
        tmp = pd.merge(tmp, tmp_before, on="customer_id", how="left")
    predict_data = pd.concat([predict_data, tmp], ignore_index=True)

predict_data.head()
```

1행

- `uselog_months` 데이터프레임의 `연월` 열에서 고유한 값들을 추출한 후 리스트로 변환하여 `year_months`에 저장한다. 즉, 데이터에 존재하는 연월을 중복 없이 리스트로 저장한다.

3행

- 루프는 `year_months` 리스트의 6번째 요소부터 마지막 요소까지 순회.
- 즉, 과거 6개월의 데이터를 기반으로 예측하기 때문에 6개월 이후의 데이터를 대상으로 한다.

4행

- `year_months[i]`에 해당하는 데이터를 `uselog_months`에서 추출하여 `tmp`에 저장합니다.
- `i`번째 달의 데이터를 선택합니다.

9행

- `tmp_before`의 `count` 열을 `count_{j-1}`로 이름을 변경합니다. 여기서 `j-1`은 이전 달을 나타낸다.
- 즉, 과거 1개월 전, 2개월 전, ... 6개월 전의 로그 수를 각각 다른 열로 저장한다.

![Untitled](/assets/HW1/gg14.png)

결과를 보면 count_pred칼럼이 예측하고 싶은달의 데이터이고 count_0이 1개월 전으로 과거 6개월 데이터를 나열한다.

결측치 포함하는 데이터 삭제후 index를 초기화한다.

```python
#결측치 제거
predict_data = predict_data.dropna()
predict_data = predict_data.reset_index(drop=True)
predict_data.head()
```

### 테크닉 37 특징이 되는 변수를 추가하자

```python
#회원기간 추가
predict_data = pd.merge(predict_data, customer[["customer_id", "start_date"]], on="customer_id", how="left")
predict_data.head()
```

```python
predict_data["now_date"] = pd.to_datetime(predict_data["연월"], format="%Y%m")
predict_data["start_date"] = pd.to_datetime(predict_data["start_date"])
from dateutil.relativedelta import relativedelta
predict_data["period"] = None
for i in range(len(predict_data)):
    delta = relativedelta(predict_data["now_date"][i], predict_data["start_date"][i])
    predict_data["period"][i] = delta.years * 12 + delta.months
predict_data.head()

```

2행

- `predict_data` 데이터프레임에서 `start_date` 열을 날짜 형식으로 변환. 이를 통해 두 날짜 간의 차이를 계산할 수 있게 된다.

3행

- `dateutil.relativedelta` 모듈에서 `relativedelta`를 가져온다.이 모듈은 두 날짜 사이의 차이를 연, 월, 일 단위로 계산할 수 있도록 도와준다.

6행

- `now_date`와 `start_date` 간의 차이를 **`relativedelta`*를 사용해 계산하여 `delta` 변수에 저장합니다. 이 차이는 연도와 월 단위로 계산된다.

7행

- 계산된 `delta` 값을 이용해 두 날짜 간의 차이를 **개월 수**로 변환하여 **`period`** 열에 저장한다.
- `delta.years * 12`는 연도를 월 단위로 변환하고, `delta.months`는 월 단위 차이를 더해준다.
- 

![Untitled](/assets/HW1/gg15.png)

### 테크닉 38 다음 달 이용 횟수를 예측하는 모델을 구축하자.

```python
#데이터를 학습용, 평가용 나눠서 학습하자.
predict_data = predict_data.loc[predict_data["start_date"] >= pd.to_datetime("20180401")]
from sklearn import linear_model
import sklearn.model_selection
model = linear_model.LinearRegression()
X = predict_data[["count_0", "count_1", "count_2", "count_3", "count_4", "count_5", "period"]]
y = predict_data["count_pred"]
X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y)
model.fit(X_train, y_train)
```

5행

- 예측을 위한 독립 변수(특징 값)들로 `count_0`, `count_1`, `count_2`, `count_3`, `count_4`, `count_5`, 그리고 `period` 열을 선택하여 `X`에 저장한다.
- 이는 이전 6개월 동안의 로그 수와 `period`(회원 기간)를 독립 변수로 설정하는 것이다.

6행

- 종속 변수(목표 값)으로 `count_pred` 열을 선택하여 `y`에 저장
- `count_pred`는 예측하려는 로그 수

7행

- 데이터를 훈련 세트와 테스트 세트로 나눈다. **`train_test_split()`** 함수는 데이터를 무작위로 분할하며, 기본적으로 75%는 훈련용, 25%는 테스트용으로 나눈다.
- `X_train`과 `y_train`은 훈련에 사용되고, `X_test`와 `y_test`는 모델 평가에 사용됩니다.

8행

- 선형 회귀 모델을 **훈련**합니다. `X_train` 데이터를 사용하여 `y_train` 값에 맞추는 방식으로 모델을 학습시킨다.

```python
#정확도 검증
print(model.score(X_train, y_train))
print(model.score(X_test, y_test))
```

둘다 60%정도의 정확도 나타냄

이렇게 회귀 예측 모델이 구축되었다. 

### 테크닉 39 모델에 기여하는 변수를 확인하자

```python
#설명 변수마다 기여하는 계수 출력
coef = pd.DataFrame({"feature_names": x.columns, "coefficient": model.coef_})
coef
```

![Untitled](/assets/HW1/gg16.png)

- `"feature_names": x.columns`: 여기서 `x.columns`는 데이터셋 `x`의 열(특징) 이름들을 의미
- `"coefficient": model.coef_`: `model.coef_`는 모델을 학습시킨 후 각 특징에 대해 계산된 계수를 담고 있다. 이 계수는 각 특징이 목표 변수에 미치는 영향을 나타낸다.

count_0가 가장 크고 과거로 거슬러 올라갈수록 기여도 작아지는 경향이 있음을 알 수 있다. 즉 이전 달의 이용 횟수가 다음 달의 이용 횟수에 영향을 미치고 있다는 것이다. 

지금까지 모델 구축부터 모델 특성까지 이해할 수 있었다. 마지막으로 적당히 변수를 만들어 예측해보자

### 테크닉 40 다음 달의 이용 횟수를 예측하자

이번에는 회원 두 명의 이용 데이터 작성해보자.

```python
#회원의 이용 이력 리스트 저장하고 데이터 작성
x1 = [3, 4, 4, 6, 8, 7, 8]
x2 = [2, 2, 3, 3, 4, 6, 8]
x_pred = [x1, x2]
#에측 진
model.predict(x_pred)
```

![Untitled](/assets/HW1/gg17.png)

첫번째는 3.8회, 두번째는 1.9회로 예측되었다. 

마지막으로 다음 장에도 사용할 수 있게 uselog_months출력해두자

```python
uselog_months.to_csv("use_log_months.csv", index=False)
```