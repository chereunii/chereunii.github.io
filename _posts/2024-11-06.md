---
layout: post
title:  "추천 시스템"
date:   2024-11-06
categories: Khuda 추천시스템
---


*해당 영상을 참고했습니다*

https://www.youtube.com/watch?v=6TP51jvjLsE

추천 시스템은 크게 두가지로 구분 가능

- **컨텐츠 기반 필터링** : 사용자의 이전 행동과 명시적 피드백을 통해 사용자가 좋아하는 것과 유사한 항목을 추천
    
    예를 들어, 사용자가 로맨스 영화 선호하면 다른 로맨스 영화 추천하는 방식
    
    **새로운 아이템**에 대한 추천이 가능하지만 사용자의 기존 관심사와 유사한 아이템만 추천하는 **다양성 부족 문제** 있을 수 있음.
    
- **협업 필터링** : 사용자와 항목간의 유사성을 동시에 사용해 추천
    
    특정 아이템을 좋아한 사용자들이 선호하는 다른 아이템 추천. 예를들어 특정 영화를 본 사람들이 자주 본 다른 영화 추천
    
    많은 데이터가 있을 때 효과적, 새로운 사용자나 아이템에 대해 추천이 어려운 **콜드 스타트 문제**가 발생할 수 있음
    

두가지를 조합한 **hybrid방식**도 가능 

Surprise 라이브러리

-추천시스템 개발을 위한 라이브러리

-다양한 모델과 데이터 제공

-scikit-learn과 유사한 사용 방법

```python
!pip install surprise --user

from surprise import SVD
from surprise import Dataset
from surprise.model_selection import cross_validate
```

```python
data=Dataset.load_builtin('ml-100k', prompt=False)
data.raw_ratings[:10] #로드한 데이터의 상위10개 평가데이터 출력
```

```
[('196', '242', 3.0, '881250949'),
 ('186', '302', 3.0, '891717742'),
 ('22', '377', 1.0, '878887116'),
 ('244', '51', 2.0, '880606923'),
 ('166', '346', 1.0, '886397596'),
 ('298', '474', 4.0, '884182806'),
 ('115', '265', 2.0, '881171488'),
 ('253', '465', 5.0, '891628467'),
 ('305', '451', 3.0, '886324817'),
 ('6', '86', 3.0, '883603013')]
```

`ml-100k`는 MovieLens에서 제공하는 영화 평가 데이터셋으로, 약 10만 개의 사용자-영화 평점 데이터가 포함되어 있다.

user-item-rating-ID 순임. 

사용자ID- 영화ID- 평점- 타임스탬프 순

→user는 196이라는 사용자가 242번의 영화를 평가를 3점으로 내림.

```python
model= SVD()
#교차검증
cross_validate(model, data, measures=['rmse', 'mae'], cv=5, verbose=True)
```

```
Evaluating RMSE, MAE of algorithm SVD on 5 split(s).

                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std
RMSE (testset)    0.9343  0.9366  0.9403  0.9281  0.9346  0.9348  0.0040
MAE (testset)     0.7342  0.7379  0.7413  0.7333  0.7370  0.7367  0.0029
Fit time          2.17    4.74    2.96    1.63    1.47    2.59    1.19
Test time         0.38    0.40    0.12    0.27    0.14    0.26    0.12

```

```
{'test_rmse': array([0.93434048, 0.93657245, 0.94031214, 0.92811956, 0.93458279]),
 'test_mae': array([0.73418184, 0.73786069, 0.74132869, 0.73325775, 0.73698824]),
 'fit_time': (2.167919635772705,
  4.743277549743652,
  2.9559719562530518,
  1.6271252632141113,
  1.4687037467956543),
 'test_time': (0.38053035736083984,
  0.4041903018951416,
  0.12397217750549316,
  0.2714107036590576,
  0.1412792205810547)}
```

- `measures=['rmse', 'mae']`: 성능 평가 지표로 RMSE와 MAE를 사용한다.
- `cv=5`: 5-폴드 교차 검증을 의미힌다. 데이터셋을 5개로 나누고 각 폴드에서 모델을 학습 및 평가하여 결과를 도출한다.
- `verbose=True`: 실행 결과를 출력한다.

### 컨텐츠 기반 필터링(Content-based Filtering)

-컨텐츠 기반 필터링은 이전의 행동과 명시적 피드백을 통해 좋아하는 것과 유사한 항목을 추천

e.g. 내가 지금까지 시청한 영화 목록과 다른 사용자의 시청 목록을 비교해 나와 비슷한 취향의 사용자가 시청한 영화를 추천

-유사도 기반으로 추천

**장점**

많은 수의 사용자를 대상으로 쉽게 확장 가능

사용자가 과심을 갖지 않던 상품 추천 가능

**단점**

-입력 특성을 직접 설계해야 해서 많은 도메인 지식이 필요

-사용자의 기존 관심사항을 기반으로만 추천 가능

```python
import numpy as np
from surprise import Dataset

data=Dataset.load_builtin('ml-100k', prompt=False)
raw_data= np.array(data.raw_ratings, dtype=int)

raw_data[:, 0]-=1 
raw_data[:, 1]-=1

n_users=np.max(raw_data[:,0]) #전체 사용자수
n_movies=np.max(raw_data[:, 1]) #전체 영화 수
shape=(n_users+1, n_movies+1)#행렬크기
shape
```

>>`(943, 1682)` #943명의 사용자와 1682개의 영화가 데이터에 포함되어있음.

- `raw_data[:, 0] -= 1`: 사용자 ID를 1씩 감소시킨다. MovieLens 데이터는 사용자 ID와 영화 ID가 1부터 시작하므로, 배열 인덱스를 맞추기 위해 0부터 시작하도록 조정하는 과정임.
- `raw_data[:, 1] -= 1`: 영화 ID도 1씩 감소시켜 0부터 시작하도록 조정한다.
- `prompt=True` (기본값): 데이터를 로드할 때, **추가 메시지**가 출력됩니다. 예를 들어, "MovieLens 데이터셋을 다운로드하시겠습니까?" 또는 "데이터셋을 로드하는 중입니다" 같은 메시지가 표시될 수 있습니다.
- `prompt=False`: 이러한 **추가 메시지를 생략**하고, 조용히 데이터를 로드합니다.

```python
adj_matrix=np.ndarray(shape, dtype=int)
for user_id, movie_id, rating, time in raw_data: #데이터 순회
  adj_matrix[user_id][movie_id]=1. #특정영화 평가하면 1로 표시
adj_matrix #인접행렬
```

- `np.ndarray(shape, dtype=int)`: 주어진 `shape` 크기의 정수형 `numpy` 배열을 생성합니다. `shape`는 이전에 정의한 `(n_users + 1, n_movies + 1)`로, 사용자 수와 영화 수에 맞춘 배열 크기입니다.
- `adj_matrix`는 사용자-영화 관계를 나타내는 **빈 행렬**로, 여기서 1은 사용자가 특정 영화를 평가했다는 것을 의미합니다

```
array([[1, 1, 1, ..., 0, 0, 0],
       [1, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0],
       ...,
       [1, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0],
       [0, 1, 0, ..., 0, 0, 0]])
```

1이 있는 위치가 현재 데이터가 있는 위치 

각 행은 사용자, 각 열은 영화를 나타냄 

```python
from collections.abc import ByteString
my_id, my_vector=0, adj_matrix[0]
best_match, best_match_id, best_match_vector=-1,-1, []

for user_id, user_vector in enumerate(adj_matrix):
  if my_id !=user_id: #자신과의 비교 피하기 위해 같은 ID는 건너뜀
    similarity= np.dot(my_vector, user_vector) #내적을 사용해 유사도 계산
    if similarity > best_match: #현재까지의 최고 유사도보다 큰 경우에만 업데이트
      best_match=similarity #최고 유사도 값을 업데이트
      best_match_id=user_id #최고 유사도 가진 사용자의 ID저장
      best_match_vector=user_vector #최고 유사도 가진 사용자 벡터 저장

print('Best match: {}, Best Match ID : {}'.format(best_match, best_match_id))
```

>>Best match: 183, Best Match ID : 275

- `my_id = 0`: 사용자 ID 0을 선택합니다.
- `my_vector = adj_matrix[0]`: `my_id`에 해당하는 인접 행렬의 벡터(사용자가 평가한 영화들)를 가져옵니다.
- `best_match`: 현재까지 찾은 최고 유사도 값을 저장합니다.
- `best_match_id`: 유사도가 가장 높은 사용자의 ID를 저장합니다.
- `best_match_vector`: 유사도가 가장 높은 사용자의 벡터를 저장합니다.
- 

```python
recommend_list = []
for i, log in enumerate(zip(my_vector, best_match_vector)):
  log1, log2 = log
  if log1 < 1 and log2 > 0.:
    recommend_list.append(i)

print(recommend_list)
```

>>[323, 324, 327, 330, 331, 332, 333, 339, 342, 345, 346, 353, 354, 355, 356, 357, 363, 364, 365, 366, 372, 374, 378, 379, 381, 382, 383, 384, 385, 386, 387, 390, 391, 392, 394, 395, 396, 398, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 412, 414, 416, 417, 418, 419, 420, 422, 424, 425, 426, 427, 428, 430, 431, 432, 435, 442, 446, 447, 448, 449, 450, 451, 452,…]

- **`log1, log2 = log`**: `log` 튜플을 각각 `log1`과 `log2`에 할당합니다. `log1`은 현재 사용자의 평가 값, `log2`는 가장 유사한 사용자의 평가 값입니다.
- `log1 < 1`: 현재 사용자가 해당 영화를 평가하지 않은 경우
- `log2 > 0`: 가장 유사한 사용자가 해당 영화를 평가한 경우.

**유클리드 거리를 사용해 추천**

```python
 my_id, my_vector=0, adj_matrix[0]
best_match, best_match_id, best_match_vector=9999,-1, []

for user_id, user_vector in enumerate(adj_matrix):
  if my_id !=user_id:
    euclidean_dist = np.sqrt(np.sum(np.square(my_vector-user_vector)))
    if euclidean_dist < best_match:
      best_match=euclidean_dist
      best_match_id=user_id
      best_match_vector=user_vector

print('Best match: {}, Best Match ID : {}'.format(best_match, best_match_id))
```

>>Best match: 14.832396974191326, Best Match ID : 737

`best_match`는 가장 짧은 유클리드 거리 값을 저장합니다. 초기값으로 매우 큰 수인 9999로 설정하여 첫 번째 비교에서 무조건 갱신되도록 합니다.

`enumerate`는 파이썬의 내장 함수로, **반복문을 돌릴 때 인덱스와 값을 동시에 얻고자 할 때** 사용됩니다. `enumerate`는 주어진 시퀀스(리스트, 튜플 등)를 인덱스와 함께 튜플 형태로 반환하여, 인덱스와 값에 동시에 접근할 수 있도록 합니다.

```python
recommend_list = []
for i, log in enumerate(zip(my_vector, best_match_vector)):
  log1, log2 = log
  if log1 < 1 and log2 > 0.:
    recommend_list.append(i)

print(recommend_list)
```

`[297, 312, 317, 342, 356, 366, 379, 384, 392, 402, 404, 407, 417, 422, 428, 433, 448, 454, 469, 473, 495, 510, 516, 526, 527, 549, 567, 602, 635, 649, 650, 654, 658, 661, 664, 696, 731, 746, 750, 754, 915, 918, 925, 929, 950, 968, 1015, 1046]`

**코사인 유사도를 사용해 추천** 

두 벡터가 이루고 있는 각을 계산

```python
def compute_cos_similarity(v1, v2):
  norm1 = np.sqrt(np.sum(np.square(v1)))
  norm2 = np.sqrt(np.sum(np.square(v2)))
  dot=np.dot(v1, v2)
  return dot / (norm1 * norm2)
```

```python
 my_id, my_vector=0, adj_matrix[0]
best_match, best_match_id, best_match_vector=-1,-1, []

for user_id, user_vector in enumerate(adj_matrix):
  if my_id !=user_id:
    cos_similarity = compute_cos_similarity(my_vector, user_vector)
    if cos_similarity > best_match:
      best_match= cos_similarity
      best_match_id=user_id
      best_match_vector=user_vector

print('Best match: {}, Best Match ID : {}'.format(best_match, best_match_id))
```

>>Best match: 0.5278586163659506, Best Match ID : 915

if cos_similarity > best_match : 현재까지의 최고 유사도보다 큰 경우:

- `best_match`를 새로운 유사도로 갱신합니다.
- `best_match_id`를 해당 사용자 ID로 갱신합니다.
- `best_match_vector`를 해당 사용자 벡터로 갱신합니다.

```python
recommend_list = []
for i, log in enumerate(zip(my_vector, best_match_vector)):
  log1, log2 = log
  if log1 < 1 and log2 > 0.:
    recommend_list.append(i)

print(recommend_list)
```

`[272, 275, 279, 280, 283, 285, 289, 294, 297, 316, 317, 355, 365, 366, 368, 379, 380, 381, 384, 386, 392, 398, 401, 404, 416, 420, 422, 424, 426, 427, 430, 432, 450, 460, 461, 466, 469, 471, 473, 474, 475, 479, 482, 483, 497, 505, 508, 510, 511, 522, 526, 527, 529, 530, 534, 536, 540, 545, 548, 549, 556, 557, 558, 560, 565, 567, 568, 569, 577, 580, 581, 582, 592, 596, 630, 635, 639, 641, 649, 651, 654, 673, 677, 678, 683, 684, 692, 696, 701, 703, 707, 708, 709, 712, 714, 719, 720, 726, 731, 734, 736, 738, 740, 745, 747, 754, 755, 761, 762, 763, 766, 780, 789, 791, 805, 819, 823, 824, 830, 843, 862, 865, 918, 929, 930, 938, 942, 943, 947, 958, 959, 960, 970, 977, 1004, 1008, 1009, 1010, 1013, 1041, 1045, 1069, 1072, 1073, 1078, 1097, 1100, 1108, 1112, 1118, 1134, 1193, 1205, 1207, 1216, 1219, 1267, 1334, 1400, 1427, 1596, 1681]`

- `zip(my_vector, best_match_vector)`: 현재 사용자(`my_vector`)와 가장 유사한 사용자(`best_match_vector`)의 벡터를 묶어 `(log1, log2)` 쌍을 생성합니다.
- `enumerate`는 각 `(log1, log2)` 쌍의 인덱스 `i`와 쌍의 값을 동시에 가져옵니다.
- `i`는 영화의 인덱스입니다.

결과는 영화 인덱스가 포함되어있다. 현재 사용자가 보지 않았지만 가장 유사한 사용자가 평가한 영화들이다.

**기존 방법에 명시적 피드백（사용자가 평가한 영화 점수）을 추가해 실험**

```python
adj_matrix=np.ndarray(shape, dtype=int)
for user_id, movie_id, rating, time in raw_data:
  adj_matrix[user_id][movie_id]=rating #해당 위치에 사용자가 해당 영화에 준 rating저장
adj_matrix
```

```
array([[5, 3, 4, ..., 0, 0, 0],
       [4, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0],
       ...,
       [5, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0],
       [0, 5, 0, ..., 0, 0, 0]])
```

기존에는 1이 들어가서 봤냐 안봤냐만 알 수 있었는데 지금은 평가점수가 몇인지 알 수 있음!

```python
 my_id, my_vector=0, adj_matrix[0]
best_match, best_match_id, best_match_vector=9999,-1, []

for user_id, user_vector in enumerate(adj_matrix):
  if my_id !=user_id:
    euclidean_dist = np.sqrt(np.sum(np.square(my_vector-user_vector)))
    if euclidean_dist < best_match:
      best_match=euclidean_dist
      best_match_id=user_id
      best_match_vector=user_vector

print('Best match: {}, Best Match ID : {}'.format(best_match, best_match_id))
```

>>`Best match: 55.06359959174482, Best Match ID : 737`

```python
 my_id, my_vector=0, adj_matrix[0]
best_match, best_match_id, best_match_vector=-1,-1, []

for user_id, user_vector in enumerate(adj_matrix):
  if my_id !=user_id:
    cos_similarity = compute_cos_similarity(my_vector, user_vector)
    if cos_similarity > best_match:
      best_match= cos_similarity
      best_match_id=user_id
      best_match_vector=user_vector

print('Best match: {}, Best Match ID : {}'.format(best_match, best_match_id))
```

>>Best match: 0.569065731527988, Best Match ID : 915

유사도계산이 어떤것인지에 따라 결과가 다르게 나옴!

### 협업 필터링(Collaborative Filtering)

- 사용자와 항목의 유사성을 동시에 고려해 추천
- 기존에 내 관심사가 아닌 항목이라도 추천 가능
- 자동으로 임베딩 학습 가능
- 장점

-자동으로 임베딩을 학습하기 때문에 도메인 지식이 필요없다.

-기존의 관심사가 아니더라도 추천 가능

- 단점

-학습 과정에 나오지 않은 항목은 임베딩을 만들 수 없음

-추가 특성을 사용하기 어려움

```python
from surprise import KNNBasic, SVD, SVDpp, NMF
from surprise import Dataset
from surprise.model_selection import cross_validate

data = Dataset.load_builtin('ml-100k', prompt=False)
```

```python
#KNN를 사용한 협업 필터링
model = KNNBasic()
cross_validate(model, data, measures=['rmse', 'mae'], cv=5, n_jobs=4, verbose=True)
```

```
Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).

                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std
RMSE (testset)    0.9749  0.9847  0.9777  0.9782  0.9780  0.9787  0.0032
MAE (testset)     0.7706  0.7765  0.7712  0.7734  0.7725  0.7728  0.0021
Fit time          1.05    1.21    1.21    1.03    1.09    1.12    0.08
Test time         12.10   12.53   12.32   12.23   3.03    10.44   3.71

```

```
{'test_rmse': array([0.97489439, 0.98472673, 0.97767411, 0.97821488, 0.97800719]),
 'test_mae': array([0.77059933, 0.77654714, 0.77120094, 0.77339804, 0.77245931]),
 'fit_time': (1.0492279529571533,
  1.2147910594940186,
  1.2083942890167236,
  1.0319266319274902,
  1.0877950191497803),
 'test_time': (12.096094846725464,
  12.534608602523804,
  12.319015979766846,
  12.229471206665039,
  3.0258262157440186)}
```

```python
#SVD를 사용한 협업 필터링
model = SVD()
cross_validate(model, data, measures=['rmse', 'mae'], cv=5, n_jobs=4, verbose=True)
```

```
Evaluating RMSE, MAE of algorithm SVD on 5 split(s).

                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std
RMSE (testset)    0.9398  0.9415  0.9289  0.9396  0.9330  0.9365  0.0048
MAE (testset)     0.7399  0.7427  0.7329  0.7387  0.7372  0.7383  0.0032
Fit time          4.73    5.23    5.13    4.80    1.72    4.32    1.31
Test time         0.52    0.52    0.49    0.30    0.14    0.39    0.15

```

```
{'test_rmse': array([0.93975043, 0.94149147, 0.92891017, 0.93956034, 0.93301531]),
 'test_mae': array([0.73993424, 0.74268224, 0.73293677, 0.73867654, 0.73717638]),
 'fit_time': (4.728437900543213,
  5.228816747665405,
  5.127328395843506,
  4.795379400253296,
  1.718987226486206),
 'test_time': (0.5218007564544678,
  0.5224308967590332,
  0.4904487133026123,
  0.29918360710144043,
  0.13797283172607422)}
```

```python
#NMF를 사용한 협업 필터링
model = NMF()
cross_validate(model, data, measures=['rmse', 'mae'], cv=5, n_jobs=4, verbose=True)
```

```
Evaluating RMSE, MAE of algorithm NMF on 5 split(s).

                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std
RMSE (testset)    0.9668  0.9668  0.9590  0.9662  0.9623  0.9642  0.0031
MAE (testset)     0.7622  0.7591  0.7517  0.7614  0.7567  0.7582  0.0038
Fit time          4.42    4.96    5.09    4.72    2.62    4.36    0.90
Test time         0.46    0.47    0.39    0.30    0.19    0.36    0.10

```

```
{'test_rmse': array([0.96681626, 0.96677469, 0.95899702, 0.96624999, 0.96227629]),
 'test_mae': array([0.76215963, 0.75906429, 0.75172075, 0.7614016 , 0.75673518]),
 'fit_time': (4.424088954925537,
  4.958595275878906,
  5.094205856323242,
  4.719755172729492,
  2.619258165359497),
 'test_time': (0.4556920528411865,
  0.4655418395996094,
  0.38816094398498535,
  0.3017566204071045,
  0.18844985961914062)}
```

```python
#SVD++를 사용한 협업 필터링
model = SVDpp()
cross_validate(model, data, measures=['rmse', 'mae'], cv=5, n_jobs=4, verbose=True)
```

```
Evaluating RMSE, MAE of algorithm SVDpp on 5 split(s).

                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std
RMSE (testset)    0.9211  0.9235  0.9242  0.9162  0.9190  0.9208  0.0029
MAE (testset)     0.7206  0.7261  0.7244  0.7181  0.7214  0.7221  0.0028
Fit time          101.12  99.69   97.00   98.55   27.88   84.85   28.52
Test time         14.14   15.38   15.20   14.74   3.34    12.56   4.63

```

```
{'test_rmse': array([0.92109084, 0.92345864, 0.92416699, 0.91622571, 0.91900971]),
 'test_mae': array([0.72063172, 0.72606685, 0.72438597, 0.71813107, 0.72138814]),
 'fit_time': (101.12036156654358,
  99.69193983078003,
  96.99841475486755,
  98.5519790649414,
  27.881733655929565),
 'test_time': (14.14368486404419,
  15.380134105682373,
  15.204987525939941,
  14.73719048500061,
  3.3447272777557373)}
```

너무 오래걸려서 사용하기 힘듦..

### 하이브리드(Hybrid)

- 컨텐츠 기반 필터링과 협업 필터링을 조합한 방식
- 많은 하이브리드 방식이 존재
- 실습에서는 협업 필터링으로 임베딩을 학습하고 컨텐츠 기반 필터링으로 유사도 기반 추천을 수행하는 추천 엔진 개발

```python
import numpy as np
from sklearn.decomposition import randomized_svd, non_negative_factorization
from surprise import Dataset

data= Dataset.load_builtin('ml-100k', prompt=False)
raw_data= np.array(data.raw_ratings, dtype=int)
raw_data[:, 0]-=1
raw_data[:, 1]-=1
```

```python
n_users = np.max(raw_data[:, 0])
n_movies = np.max(raw_data[:, 1])
shape = (n_users+1, n_movies+1)
shape
```

>>`(943, 1682)`

```python
adj_matrix = np.ndarray(shape, dtype=int)
for user_id, movie_id, rating, time in raw_data:
  adj_matrix[user_id][movie_id] = rating
adj_matrix
```

```
array([[5, 3, 4, ..., 0, 0, 0],
       [4, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0],
       ...,
       [5, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0],
       [0, 5, 0, ..., 0, 0, 0]])
```

```python
U, S, V = randomized_svd(adj_matrix, n_components=2)
S= np.diag(S)
U.shape, S.shape, V.shape
```

>>`((943, 2), (2, 2), (2, 1682))`

```python
np.matmul(np.matmul(U, S), V)
```

```
array([[ 3.91732673e+00,  1.47276646e+00,  7.98262072e-01, ...,
         6.24907930e-04,  1.41100866e-02,  1.36545894e-02],
       [ 1.85777220e+00,  3.96191062e-01,  5.05705334e-01, ...,
         5.38862788e-03,  1.77236664e-03,  5.26953740e-04],
       [ 8.94989133e-01,  1.71578407e-01,  2.51738346e-01, ...,
         2.92094640e-03,  5.39930720e-04, -1.25740835e-04],
       ...,
       [ 9.92051643e-01,  2.10814874e-01,  2.70363057e-01, ...,
         2.89019054e-03,  9.34215587e-04,  2.66605131e-04],
       [ 1.30425380e+00,  5.27669944e-01,  2.50080165e-01, ...,
        -4.20678535e-04,  5.30525926e-03,  5.28070247e-03],
       [ 2.82999398e+00,  9.70812223e-01,  6.15871607e-01, ...,
         2.02091459e-03,  8.67740517e-03,  8.03107550e-03]])
```

#사용자 기반 추천

```python
 my_id, my_vector=0,U[0]
best_match, best_match_id, best_match_vector=-1,-1, []

for user_id, user_vector in enumerate(U):
  if my_id !=user_id:
    cos_similarity = compute_cos_similarity(my_vector, user_vector)
    if cos_similarity > best_match:
      best_match= cos_similarity
      best_match_id=user_id
      best_match_vector=user_vector

print('Best match: {}, Best Match ID : {}'.format(best_match, best_match_id))
```

>>Best match: 0.9999942291516859, Best Match ID : 235

```python
recommend_list = []
for i, log in enumerate(zip(adj_matrix[my_id], adj_matrix[best_match_id])):
  log1, log2 = log
  if log1 < 1 and log2 > 0.:
    recommend_list.append(i)

print(recommend_list)
```

>>[272, 273, 274, 281, 285, 288, 293, 297, 303, 306, 312, 317, 327, 332, 369, 410, 418, 419, 422, 426, 428, 431, 434, 442, 461, 475, 477, 482, 495, 503, 504, 505, 506, 509, 519, 520, 522, 525, 531, 545, 548, 590, 594, 595, 613, 631, 654, 658, 660, 672, 684, 685, 691, 695, 698, 704, 716, 728, 734, 749, 755, 863, 865, 933, 1012, 1038, 1101, 1327, 1400]

```python
 my_id, my_vector=0,V.T[0]
best_match, best_match_id, best_match_vector=-1,-1, []

for user_id, user_vector in enumerate(V.T):
  if my_id !=user_id:
    cos_similarity = compute_cos_similarity(my_vector, user_vector)
    if cos_similarity > best_match:
      best_match= cos_similarity
      best_match_id=user_id
      best_match_vector=user_vector

print('Best match: {}, Best Match ID : {}'.format(best_match, best_match_id))
```

>>Best match: 0.999999994914872, Best Match ID : 1287

```
for user_id, user_vector in enumerate(V.T):

```

```python
recommend_list = []
for i, user_vector in enumerate(adj_matrix):
  if adj_matrix[my_id][i] > 0.9:
    recommend_list.append(i)

print(recommend_list)
```

>>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, …]

```python
adj_matrix
```

```
array([[5, 3, 4, ..., 0, 0, 0],
       [4, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0],
       ...,
       [5, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0],
       [0, 5, 0, ..., 0, 0, 0]])
```

```python
A , B ,iter = non_negative_factorization(adj_matrix, n_components=2)
np.matmul(A, B)
```

```
array([[3.71107433e+00, 1.48461856e+00, 7.39541570e-01, ...,
        3.64501983e-03, 1.45513751e-02, 1.44116215e-02],
       [2.11729713e+00, 2.37145679e-01, 5.51637757e-01, ...,
        4.76290749e-03, 2.84605931e-05, 0.00000000e+00],
       [9.85325089e-01, 1.10360320e-01, 2.56715279e-01, ...,
        2.21651094e-03, 1.32446864e-05, 0.00000000e+00],
       ...,
       [1.04478344e+00, 1.17019891e-01, 2.72206478e-01, ...,
        2.35026384e-03, 1.40439224e-05, 0.00000000e+00],
       [1.45769331e+00, 5.42108391e-01, 2.99217251e-01, ...,
        1.61232500e-03, 5.15892655e-03, 5.10748255e-03],
       [2.44709957e+00, 9.41278705e-01, 4.95671746e-01, ...,
        2.56934867e-03, 9.08400301e-03, 8.99501717e-03]])
```

**#항목기반추천**

```python
 my_id, my_vector=0,U[0]
best_match, best_match_id, best_match_vector=-1,-1, []

for user_id, user_vector in enumerate(U):
  if my_id !=user_id:
    cos_similarity = compute_cos_similarity(my_vector, user_vector)
    if cos_similarity > best_match:
      best_match= cos_similarity
      best_match_id=user_id
      best_match_vector=user_vector

print('Best match: {}, Best Match ID : {}'.format(best_match, best_match_id))
```

>>Best match: 0.9999942291516859, Best Match ID : 235

```python
recommend_list = []
for i, log in enumerate(zip(adj_matrix[my_id], adj_matrix[best_match_id])):
  log1, log2 = log
  if log1 < 1 and log2 > 0.:
    recommend_list.append(i)

print(recommend_list)
```

>>[272, 273, 274, 281, 285, 288, 293, 297, 303, 306, 312, 317, 327, 332, 369, 410, 418, 419, 422, 426, 428, 431, 434, 442, 461, 475, 477, 482, 495, 503, 504, 505, 506, 509, 519, 520, 522, 525, 531, 545, 548, 590, 594, 595, 613, 631, 654, 658, 660, 672, 684, 685, 691, 695, 698, 704, 716, 728, 734, 749, 755, 863, 865, 933, 1012, 1038, 1101, 1327, 1400]

**#사용자 기반 추천**

```python
 my_id, my_vector=0,V.T[0]
best_match, best_match_id, best_match_vector=-1,-1, []

for user_id, user_vector in enumerate(V.T):
  if my_id !=user_id:
    cos_similarity = compute_cos_similarity(my_vector, user_vector)
    if cos_similarity > best_match:
      best_match= cos_similarity
      best_match_id=user_id
      best_match_vector=user_vector

print('Best match: {}, Best Match ID : {}'.format(best_match, best_match_id))
```

Best match: 0.9999999948793713, Best Match ID : 1287

```python
recommend_list = []
for i, user_vector in enumerate(adj_matrix):
  if adj_matrix[my_id][i] > 0.9:
    recommend_list.append(i)

print(recommend_list)
```

`[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 22... 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271]`

```python
adj_matrix
```

```
array([[5, 3, 4, ..., 0, 0, 0],
       [4, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0],
       ...,
       [5, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0],
       [0, 5, 0, ..., 0, 0, 0]])
```

```python
A , B ,iter = non_negative_factorization(adj_matrix, n_components=2)
np.matmul(A, B)
```

```
array([[3.71107433e+00, 1.48461856e+00, 7.39541570e-01, ...,
        3.64501983e-03, 1.45513751e-02, 1.44116215e-02],
       [2.11729713e+00, 2.37145679e-01, 5.51637757e-01, ...,
        4.76290749e-03, 2.84605930e-05, 0.00000000e+00],
       [9.85325089e-01, 1.10360320e-01, 2.56715279e-01, ...,
        2.21651094e-03, 1.32446863e-05, 0.00000000e+00],
       ...,
       [1.04478344e+00, 1.17019891e-01, 2.72206478e-01, ...,
        2.35026384e-03, 1.40439223e-05, 0.00000000e+00],
       [1.45769331e+00, 5.42108391e-01, 2.99217251e-01, ...,
        1.61232500e-03, 5.15892655e-03, 5.10748255e-03],
       [2.44709957e+00, 9.41278705e-01, 4.95671746e-01, ...,
        2.56934867e-03, 9.08400301e-03, 8.99501717e-03]])
```

```python
 my_id, my_vector=0,U[0]
best_match, best_match_id, best_match_vector=-1,-1, []

for user_id, user_vector in enumerate(U):
  if my_id !=user_id:
    cos_similarity = compute_cos_similarity(my_vector, user_vector)
    if cos_similarity > best_match:
      best_match= cos_similarity
      best_match_id=user_id
      best_match_vector=user_vector

print('Best match: {}, Best Match ID : {}'.format(best_match, best_match_id))
```

Best match: 0.9999942297669374, Best Match ID : 235

```python
recommend_list = []
for i, user_vector in enumerate(adj_matrix):
  if adj_matrix[my_id][i] > 0.9:
    recommend_list.append(i)

print(recommend_list)
```

[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 37, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87..]