---
layout: post
title:  "9장 잠재고객을 파악하기 위한 이미지 인식 테크닉 10"
date:   2024-11-02 
categories: Khuda 데이터분석 실무
---

### 테크닉 81 이미지 데이터를 불러오자

```python
import cv2
img = cv2.imread("img/img01.jpg") #변수에 저장
height, width = img.shape[:2]
print("이미지 가로: " + str(width))
print("이미지 세로: " + str(height))
cv2.imshow("img", img) #불러온 이미지를 화면에 표시
cv2.waitKey(0)#키입력 대기, 아무키나 누르면 창이 닫힘.
```

![Untitled](/assets/HW1/jj1.png)


- waitKey: 몇 초동안 이미지 표시할지 밀리초(ms)단위로 지정할 수 있음. 1000을 지정시 1초간표시, 여기서 0인데, 윈도우 닫을 때까지 계속해서 보여주는 경우임.

### 테크닉 82 동영상 데이터를 불러오자

```python
import cv2

# 정보 취득 #
cap = cv2.VideoCapture("mov/mov01.avi")
width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)
height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)
count = cap.get(cv2.CAP_PROP_FRAME_COUNT) #비디오 총 프레임 수
fps = cap.get(cv2.CAP_PROP_FPS) #비디오의 초당 프레임 수 
print("가로: " + str(width))
print("세로: " + str(height))
print("총 프레임수: " + str(count))
print("FPS: " + str(fps))

# 출력 #
while(cap.isOpened()):
    ret, frame = cap.read()
    if ret:
        cv2.imshow("frame", frame)
        if cv2.waitKey(1) & 0xFF == ord("q"):
            break
cap.release()
cv2.destroyAllWindows()
```

- while 문에서 cap에 저장된 동영상 정보를 프레임마다 처리하고 각 프레임의 정보를 함수 read로 읽어 들인다. frame에 저장된 정보는 이미지 정보라 imshow로 표시가능. 모든 프레임 처리하거나 q키를 클릭하면 종료한다.

### 테크닉 83 동영상을 이미지로 나누고 저장하자

```python
filepath = "snapshot/snapshot_" + str(num) + ".jpg"#저장할 파일경로 및 파일명 생성
cv2.imwrite(filepath, frame) #filepath경로에 저장
```

- 이미지 저장에는 함수imwrite 사용

![Untitled](/assets/HW1/jj2.png)


### 테크닉 84 이미지 속에 사람이 어디에 있는지 검출해 보자

사람을 간단하게 인식하기 위해 ‘**HOG특징량**’ 사용. HOG: Histogram of Oriented Gradients의 약자로 휘**도의 기울기** 라고 설명할 수 있으며, 사람 실루엣 형태의 특징을 위치나 각도록 표현한 것이라고 생각하면 쉽다.

```python
import cv2

# 준비 #
hog = cv2.HOGDescriptor()
hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())
hogParams = {'winStride': (8, 8), 'padding': (32, 32), 'scale': 1.05, 'hitThreshold': 0, 'finalThreshold': 5}

# 검출 #
img = cv2.imread("img/img01.jpg")
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
human, r = hog.detectMultiScale(gray, **hogParams)
if (len(human) > 0):
    for (x, y, w, h) in human:
        cv2.rectangle(img, (x, y), (x + w, y + h), (255, 255, 255), 3) #사각형 그려 표시
cv2.imshow("img", img)
cv2.waitKey(0)
```

- `winStride`: 검색 윈도우의 이동 간격을 지정합
- `padding`: 패딩 크기를 설정하여 검출 정확도를 높인다.
- `scale`: 이미지 피라미드의 스케일링 비율을 설정하여 멀리 있는 객체를 찾을 때 유용
- `hitThreshold`: 검출할 때 점수를 조정하는 임계값입니다.
- `finalThreshold`: 최종 검출할 객체의 최소 신뢰도를 설정합니다.

### 테크닉 85 이미지 속 사람 얼굴을 검출해 보자

```python
import cv2

# 준비 #
cascade_file = "haarcascade_frontalface_alt.xml"
cascade = cv2.CascadeClassifier(cascade_file)

# 검출 #
img = cv2.imread("img/img02.jpg")
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #그레이스케일로 변환해 저장
face_list = cascade.detectMultiScale(gray, minSize=(50, 50)) #검출할 최소크기 지정

# 검출한 얼굴 표시하기
for (x, y, w, h) in face_list:
    color = (0, 0, 225)
    pen_w = 3
    cv2.rectangle(img, (x, y), (x + w, y + h), color, thickness=pen_w)

cv2.namedWindow("img", cv2.WINDOW_NORMAL)
cv2.imshow("img", img) #검출된 얼굴이 표시된 이미지를 화면에 표시
cv2.imwrite("temp.jpg", img) #얼굴에 표시된 이미지를 파일로 저장
cv2.waitKey(0)
cv2.destroyAllWindows()
```

### 테크닉 86 이미지 속 사람의 얼굴이 어느 쪽을 보고 있는지 검출해보자

dlib라는 라이브러리를 이용하면 얼굴을 얼굴 랜드마크라고 부르는 눈, 코, 입, 윤곽의 68개 특징점으로 표현할 수 있다. 이것으로 사람이 얼굴을 어느 쪽으로 돌리고 있는지와 같은 세세한 정보 검출할 수 있다.

```python
import cv2
import dlib
import math

# 준비 #
predictor = dlib.shape_predictor("shape_predictor_68_face_landmarks.dat")
detector = dlib.get_frontal_face_detector()

# 검출 #
img = cv2.imread("img/img02.jpg")
dets = detector(img, 1) #1은 업샘플링 횟수를 의미해 얼굴 검출의 정확도를 높인다. 

for k, d in enumerate(dets): #k는 얼굴의 인덱스, d는 얼굴의 위치 나타냄.
    shape = predictor(img, d)

    # 얼굴 영역 표시
    color_f = (0, 0, 225) #얼굴 영역의 테두리를 그릴때 사용할 색상을 설정, 빨강
    color_l_out = (255, 0, 0) #외부선 색상 설정, 파랑
    color_l_in = (0, 255, 0) #내부 선 색상, 녹색
    line_w = 3 #사각형 선의 두께 설정
    circle_r = 3 #원의 반지름 설정
    fontType = cv2.FONT_HERSHEY_SIMPLEX #텍스트 표시할 때 사용할 글꼴 설정
    fontSize = 1 #텍스트 크기 설정

    cv2.rectangle(img, (d.left(), d.top()), (d.right(), d.bottom()), color_f, line_w)
    cv2.putText(img, str(k), (d.left(), d.top()), fontType, fontSize, color_f, line_w)

```

- predictor = dlib.shape_predictor("shape_predictor_68_face_landmarks.dat")

: 68개 얼굴 랜드마크를 예측하는 모델 파일을 사용하여 `predictor` 객체를 생성. 이 객체는 얼굴의 주요 특징점을 검출하는 데 사용된다.

```python
# 중심을 계산할 사각형 준비
num_of_points_out = 17 #얼굴 바깥쪽 랜드마크 포인트 개수 설정
num_of_points_in = shape.num_parts - num_of_points_out #얼굴 안쪽 랜드마크 포인트 개수 계산
gx_out = 0 #초기화
gy_out = 0
gx_in = 0
gy_in = 0

for shape_point_count in range(shape.num_parts): 
    shape_point = shape.part(shape_point_count)
    #print("얼굴 랜드마크No.{} 좌표위치: ({},{})".format(shape_point_count, shape_point.x, shape_point.y))

    # 얼굴 랜드마크마다 그리기
    if shape_point_count < num_of_points_out:
        cv2.circle(img, (shape_point.x, shape_point.y), circle_r, color_l_out, line_w)#바깥쪽 랜드마크 포인트 위치에 원 그려 표시
         #바깥쪽 랜드마크 포인트의 x,y좌표 값을 누적해 평균 구할 준비 한다.
        gx_out = gx_out + shape_point.x / num_of_points_out
        gy_out = gy_out + shape_point.y / num_of_points_out
    else:  #안쪽 랜드마크 포인트 위치에 원 그려 표시
        cv2.circle(img, (shape_point.x, shape_point.y), circle_r, color_l_in, line_w
        gx_in = gx_in + shape_point.x / num_of_points_in 
        gy_in = gy_in + shape_point.y / num_of_points_in

# 중심위치 표시
cv2.circle(img, (int(gx_out), int(gy_out)), circle_r, (0, 0, 255), line_w)
cv2.circle(img, (int(gx_in), int(gy_in)), circle_r, (0, 0, 0), line_w)

# 얼굴 방향 표시
theta = math.asin(2 * (gx_in - gx_out) / (d.right() - d.left()))
radian = theta * 180 / math.pi

```

```python
# 얼굴 방향 표시
if radian < 0: #음수일 경우 얼굴 방향 왼쪽으로 설정
    textPrefix = "left "
else:
    textPrefix = "right "
#얼굴 방향 텍스트 구성한다. 
textShow = textPrefix + str(round(abs(radian), 1)) + " deg."
cv2.putText(img, textShow, (d.left(), d.top()), fontType, fontSize, color_f, line_w)

cv2.namedWindow("img", cv2.WINDOW_NORMAL)
cv2.imshow("img", img)
cv2.imwrite("temp.jpg", img)
cv2.waitKey(0)
cv2.destroyAllWindows()

```

![Untitled](/assets/HW1/jj3.png)

### 테크닉 87 검출한 정보를 종합해서 타임랩스를 만들어보자

```python
movie_name = "timelapse.avi"
fourcc = cv2.VideoWriter_fourcc('X', 'V', 'I', 'D')
video = cv2.VideoWriter(movie_name, fourcc, 30, (Width, Height))
video.write(frame)

video.release()
```

2. 비디오 코덱을 설정. `'XVID'` 코덱을 사용하여 비디오 파일을 저장. `fourcc`는 FourCC (Four Character Code)로, 비디오 코덱을 나타내는 고유 코드이다.

### 테크닉 88 전체 모습을 그래프로 가시화해보자

```python
import pandas as pd

list_df = pd.DataFrame(columns=['time', 'people'])#시간 지남에 따라 사람 수 저장할 용도로 사용

tmp_se = pd.Series([num/fps, len(human)], index=list_df.columns)
list_df = list_df.append(tmp_se, ignore_index=True)

import matplotlib.pyplot as plt
plt.plot(list_df["time"], list_df["people"], label="test")
plt.show()
```

- `num/fps`는 현재 시간을 의미하며, `len(human)`은 현재 프레임에서 검출된 사람의 수를 나타낸다. `index=list_df.columns`를 사용해 데이터프레임 `list_df`의 컬럼 이름을 인덱스로 지정한다.

![Untitled](/assets/HW1/jj4.png)


### 테크닉 89 거리의 변화를 그래프로 확인해보자

```python
cap = cv2.VideoCapture("mov/mov02.avi")
```

`mov02.avi` 비디오 파일을 읽어와 `cap`이라는 비디오 캡처 객체를 생성. 이 객체는 비디오 프레임을 하나씩 읽어오는 데 사용된다. OpenCV의 `VideoCapture` 클래스는 비디오 파일이나 카메라에서 비디오 스트림을 가져오는 기능을 제공한다.

### 테크닉 90 이동 평균을 계산해서 노이즈를 제거하자

노이즈는 계산해야 할 사람을 계산하지 않아서 생기는 오차와 반대로 계산하지 않아도 될 것을 계산해서 생기는 오차이다. 

```python
import numpy as np

def moving_average(x, y):
    y_conv = np.convolve(y, np.ones(5) / float(5), mode='valid')
    x_dat = np.linspace(np.min(x), np.max(x), np.size(y_conv))
    return x_dat, y_conv
```

- y_conv = np.convolve(y, np.ones(5) / float(5), mode='valid'):

`y` 데이터에 대해 길이 5의 이동 평균을 계산합니다. `np.ones(5) / float(5)`는 크기가 5인 배열 `[1/5, 1/5, 1/5, 1/5, 1/5]`을 생성하여, `y`와 합성곱을 수행하여 이동 평균을 구한다. `mode='valid'`는 유효한 영역만 반환하여 경계 값을 제외한다.

- x_dat = np.linspace(np.min(x), np.max(x), np.size(y_conv)):

`x`의 최소값과 최대값 사이에 `y_conv`와 같은 크기의 등간격 데이터를 생성하여 `x_dat`에 저장한다. 이는 `y_conv`와 `x` 간의 대응을 맞추기 위해 사용된다.

```python
plt.plot(list_df["time"], list_df["people"], label="raw")
max_x, max_y = moving_average(list_df["time"], list_df["people"])
plt.plot(max_x, max_y, label="average")#이동 평균 데이터를 그래프로 그리기
plt.xlabel("time (sec.)")
plt.ylabel("population")
plt.ylim(0, 15)
plt.legend()
plt.show()
```

![Untitled](/assets/HW1/jj5.png)