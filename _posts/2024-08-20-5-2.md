---
layout: post
title:  "05-2 교차 검증과 그리드 서치"
date:   2024-08-20
categories: [Khuda, week5]
---

테스트 세트로 일반화 성능을 올바르게 예측하려면 가능한 테스트 세트를 사용하지 말고, 모델을 만들고 마지막에 딱 한번만 사용하는 것이 좋다. 

### 검증 세트

테스트 세트를 사용하지 않으면 모델이 과대적합인지 과소적합인지 판단하기 어렵다. 테스트를 사용하지 않고 이를 측정하는 간단한 방법은 훈련세트를 또 나누는 것이다. 이 데이터를 **검증세트** 라고 부른다. 훈련세트 80% 중 20%를 검증세트로 만든다. 

![Untitled](/assets/HW1/bb8.png)

```python
import pandas as pd
wine= pd.read_csv('https://bit.ly/wine-date')

#class열을 타깃으로 사용, 나머지 열은 특성 배열에 저장
data=wine[['alcohol','sugar','pH']].to_numpy()
target=wine['class'].to_numpy()
```

```python
#훈련세트와 테스트 세트 나누기
from sklearn.model_selection import train_test_split
train_input, test_input, train_target, test_target= train_test_split(data, target, test_size=0.2, random_state=42)
```

train_input과 train_target을 다시 train_test_split()함수에 넣어 훈련 세트 sub_input, sub_target과 검증세트 val_input, val_target을 만든다. 여기에서도 test_size매개변수를 0.2로 지정해 train_input의 약 20%를 val_input으로 만든다.

```python

sub_input, val_input, sub_target, val_target= train_test_split(train_input, train_target, test_size=0.2, random_state=42)
```

```python
print(sub_input.shape, val_input.shape)
```

>> (4157, 3) (1040, 3)

원래 5197개였던 훈련 세트가 4157개로 줄고 검증 세트는 1040개.

```python
from sklearn.tree import DecisionTreeClassifier
dt= DecisionTreeClassifier(random_state=42)
dt.fit(sub_input, sub_target)
print(dt.score(sub_input, sub_target))
```

>>0.9971133028626413
>>0.864423076923077

훈련 세트에 과대적합 된 것을 볼 수 있다.


### 교차 검증

검증 세트를 만드느라 훈련 세트가 줄었다. **교차 검증**으로 안정적인 검증 점수를 얻고 훈련에 더 많은 데이터를 사용할 수 있다. 

교차 검증은 검증 세트를 떼어 내어 평가하는 과정을 여러 번 반복한다. 그다음 이 점수를 평균해 최종 검증 점수를 얻는다. 

![Untitled](/assets/HW1/bb9.png)

이 그림은 3-폴드 교차 검증이다. 

**3-폴드 교차 검증:** 훈련 세트를 세 부분으로 나눠서 교차 검증을 수행하는 것. (k-폴드 교차 검증)

cross_validate(): 교차 검증 함수, 기본적으로 5-폴드 교차 검증 수행. 

```python
from sklearn.model_selection import cross_validate
scores= cross_validate(dt, train_input, train_target)
print(scores)
```

>>{'fit_time': array([0.03625059, 0.02982235, 0.03837943, 0.01764607, 0.015172  ]), 'score_time': array([0.01000404, 0.002213  , 0.01130247, 0.00223064, 0.00227547]), 'test_score': array([0.86923077, 0.84615385, 0.87680462, 0.84889317, 0.83541867])}

이 함수는 fit_time, score_time, test_score키를 가진 딕셔너리 반환한다. 처음 2개의 키는 각각 모델을 훈련하는 시간과 검증하는 시간을 의미한다. 각 키마다 5개의 숫자가 담겨있다. 

교차검증의 최종 점수는 test_score키에 담긴 5개의 점수를 평균하여 얻을 수 있다. 

fit_time과 score_time세트는 상황에 따라 결과 달라짐. 

```python
import numpy as np
print(np.mean(scores['test_score']))
```

>> 0.855300214703487

주의할 점은 cross_validate()훈련 세트를 섞어 폴드를 나누지 않는다. 앞서 우리는 train_test_split()함수로 전체 데이터를 섞은 후 훈련세트를 준비했기에 따로 섞을 필요가 없다. 

```python
from sklearn.model_selection import StratifiedKFold
scores= cross_validate(dt, train_input, train_target, cv=StratifiedKFold())
print(np.mean(scores['test_score']))
```

>> 0.855300214703487

cross_validate()함수는 기본적으로 회귀모델일 경우 KFold분할기를 사용하고 분류 모델일 경우 타깃 클래스를 골고루 나누기 위해 StratifiedKFold를 사용한다. 

```python
#훈련 세트 섞은 후 10-폴드 교차 검증 수행시
splitter= StratifiedKFold(n_splits=10, shuffle=True, random_state=42)
scores= cross_validate(dt, train_input, train_target, cv=splitter)
print(np.mean(scores['test_score']))
```

>>0.8574181117533719
>>

### 하이퍼파라미터 튜닝

**하이퍼파라미터**: 모델이 학습할 수 없어 사용자가 지정해야만 한다. 

GfidSearchCV클래스는 하이퍼파라미터 탐색과 교차 검증을 한 번에 수행한다. 별도로 cross_validate()함수를 호출할 필요가 없다. 

```python
from sklearn.model_selection import GridSearchCV
params= {'min_impurity_decrease': [0.0001, 0.0002, 0.0003, 0.0004, 0.0005]}

#그리드 서치 객체 생성
gs= GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1)
#그리드 서치 모델 훈련
gs.fit(train_input, train_target)
```

`min_impurity_decrease`는 트리의 노드를 분할할 때 노드의 불순도 감소가 이 값 이상이어야 분할을 수행하는 것을 의미한다. 이 값이 클수록 트리가 단순해지고, 작을수록 트리가 복잡해진다.

`GridSearchCV`는 하이퍼파라미터의 최적 조합을 찾기 위해 다양한 조합을 시도하는 기법. cv의 기본값은 5이다. 

`params`는 테스트할 하이퍼파라미터의 범위를 지정하는 딕셔너리

`n_jobs=-1` -1로 지정하면 모든 사용 가능한 CPU 코어를 사용하여 병렬로 작업을 수행하도록 지정. 기본값은 1임.

```python
#학습데이터 성능평가
dt= gs.best_estimator_
print(dt.score(train_input, train_target))
```

>> 0.9615162593804117

```python
print(gs.best_params_) #최적의 매개변수 출력
```

>>{'min_impurity_decrease': 0.0001}

0.0001이 가장 좋은 값으로 선택되었다.

```python
#5번의 교차 검증으로 얻은 점수 출력
print(gs.cv_results_['mean_test_score'])
```

>>[0.86819297 0.86453617 0.86492226 0.86780891 0.86761605]

첫 번째 값이 가장 크다. 

```python
#가장 큰 값의 인덱스 출력
best_index= np.argmax(gs.cv_results_['mean_test_score'])
print(gs.cv_results_['params'][best_index])
```

>>{'min_impurity_decrease': 0.0001}

이 과정을 정리해보면, 

1. 먼저 탐색한 매개변수를 지정한다.
2. 그다음 훈련 세트에서 그리드 서치를 수행해 최상의 평균 검증 점수가 나오는 매개변수 조합을 찾는다. 이 조합은 그리드 서치 객체에 저장된다.
3. 그리드 서치는 최상의 매개변수에서(교차 검증에 사용한 훈련 세트가 아니라) 전체 훈련 세트를 사용해 최종 모델을 훈련한다. 이 모델도 그리드 서치 객체에 저장된다. 

```python
params= {'min_impurity_decrease': np.arange(0.0001, 0.001, 0.0001),
         'max_depth': range(5,20,1),
         'min_samples_split': range(2,100,10)}
```

**넘파이 arange()함수**는 첫 번째 매개변수 값에서 시작해 두 번째 매개변수에 도달할 때까지 세 번째 매개변수를 계속 더한 배열을 만든다. 코드에서 0.0001에서 시작해 0.001이 될 때까지 0.0001을 계속 더한 배열. 원소 총 9개.

파이썬 range()함수도 비슷한데 정수만 사용할 수 있음. 이 경우 max_depth를 5에서 20까지 1씩 증가하며 15개의 값 만든다. min_samples_split은 2에서 100까지 10씩 증가하며 10개 만든다.

따라서 이 매개변수로 수행할 교차 검증 횟수는 9*15*10 =1350개이다. 

```python
gs= GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1)
gs.fit(train_input, train_target)
#최상의 매개변수 조합 확인
print(gs.best_params_)
```

>>{'max_depth': 14, 'min_impurity_decrease': 0.0004, 'min_samples_split': 12}

```python
#최상의 교차 검증 점수 확인
print(np.max(gs.cv_results_['mean_test_score']))
```

>>0.8683865773302731


### 랜덤 서치

매개변수 값이 수치일 때 값의 범위나 간격을 미리 정하기 어렵고, 너무 많은 매개 변수 조건이 있어 그리드 서치 수행 시간이 오래걸릴 수 있는데 이럴 때 **랜덤 서치**를 사용하면 좋다. 

```python
from scipy.stats import uniform, randint
rgen= randint(0,10)
rgen.rvs(10)#숫자 10개 샘플링
```

>>`array([6, 4, 7, 9, 1, 7, 0, 7, 3, 0])`
uniform과 randint클래스는 모두 주어진 범위에서 고르게 값을 뽑는다. 

```python
np.unique(rgen.rvs(1000), return_counts=True)
```

>>array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),
 array([ 97, 106, 109, 102, 106,  68,  99, 121, 104,  88])

첫 번째 배열은 고유한 값들, 두 번째 배열은 각 고유한 값이 나타난 횟수이다.

```python
#0~1사이 10개 실수
ugen= uniform(0,1)
ugen.rvs(10)

```

>>array([0.09148147, 0.39823754, 0.69753403, 0.27692482, 0.45708019,  0.748051  , 0.64300659, 0.27654642, 0.73444711, 0.26972511])

```python
params={'min_impurity_decrease': uniform(0.0001, 0.001),
        'max_depth':randint(20,50),
        'min_samples_split':randint(2,25),
        'min_samples_leaf': randint(1,25)}
```

```python
from sklearn.model_selection import RandomizedSearchCV
gs= RandomizedSearchCV(DecisionTreeClassifier(random_state=42), params, n_iter=100, n_jobs=-1, random_state=42)
gs.fit(train_input, train_target)
#매개변수 조합 출력
print(gs.best_params_)
```

>>{'max_depth': 39, 'min_impurity_decrease': 0.00034102546602601173, 'min_samples_leaf': 7, 'min_samples_split': 13}

```python
#최고의 교차 검증 점수 확인
print(np.max(gs.cv_results_['mean_test_score']))
```

>>0.8695428296438884

```python
dt= gs.best_estimator_
print(dt.score(test_input, test_target))
```

>>0.86

정리

- **검증 세트**: 하이퍼파라미터 튜닝을 위해 모델을 평가할 때 테스트 세트를 사용하지 않기 위해 훈련 세트에서 다시 떼어 낸 데이터 세트이다.
- **교차 검증**: 훈련 세트를 여러 폴드로 나눈 다음 한 폴드가 검증 세트의 역할을 하고 나머지 폴드에서는 모델 훈련. 교차 검증은 이런 식으로 폴드에 대해 검증 점수를 얻어 평균하는 방법.
- **그리드 서치**: 하이퍼파라미터 탐색을 자동화해주는 도구. 탐색할 매개변수를 나열하면 교차 검증을 수행하여 가장 좋은 검증 점수의 매개변수조합을 선택한다. 마지막으로 이 매개변수 조합으로 최종 모델을 훈련한다.
- **랜덤 서치:** 연속된 매개변수 값을 탐색할 때 유용. 탐색할 값을 직접 나열하는 것이 아니고 탐색 값을 샘플링할 수 있는 확률 분포 객체를 전달한다.지정된 횟수만큼 샘플링하여 교차 검증을 수행하기 때문에 시스템 자원이 허락하는 만큼 탁색량을 조절할 수 있다.
